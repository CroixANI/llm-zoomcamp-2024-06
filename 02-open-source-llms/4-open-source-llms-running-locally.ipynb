{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd39cbcc-e713-4038-ae4f-6b425fe62f2f",
   "metadata": {},
   "source": [
    "# Pre-Requisites\n",
    "## Install [Ollama](https://github.com/ollama/ollama)\n",
    "\n",
    "```cmd\n",
    "curl -fsSL https://ollama.com/install.sh | sh\n",
    "```\n",
    "\n",
    "## Run Ollama\n",
    "\n",
    "```cmd\n",
    "ollama start\n",
    "```\n",
    "\n",
    "## Run New Terminal and run model\n",
    "\n",
    "```cmd\n",
    "ollama run phi3\n",
    "```\n",
    "\n",
    "## Run Jupyter Notebook\n",
    "\n",
    "```cmd\n",
    "pipenv shell\n",
    "pipenv run jupyter notebook\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039ff9c5-ab8f-410c-86a6-d29487e450a9",
   "metadata": {},
   "source": [
    "# Running Ollama and Phi3 Model Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43d26e18-50b8-4566-a450-9f9c24a9496b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - When will the course start?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('../01-intro/documents.json', 'rt') as f_in:\n",
    "    docs_raw = json.load(f_in)\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course_dic in docs_raw:\n",
    "    for doc in course_dic['documents']:\n",
    "        doc['course'] = course_dic['course']\n",
    "        documents.append(doc)\n",
    "\n",
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f02617ba-daf8-40c2-a971-219c3116ece0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0xffff72614e90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import minsearch\n",
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01dedd97-8d27-4f60-aae3-aaa87b739e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "    api_key='ollama',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf0e1c79-aaa5-4d58-a1aa-2d92aa6961c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt\n",
    "\n",
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "def llm(prompt, generate_params=None):\n",
    "    response = client.chat.completions.create(\n",
    "        model='phi3',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a42a215-7a4f-4aa5-9b8a-15020ff33bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' This is a test.\\n\\n\\nThe instruction seems to be simple, asking for the writing of just one sentence with specific content and purpose in mind – confirming whether an environment or system works correctly by executing what appears to be straightforward commands. The simplicity lies both in its directness (a command that should yield minimal output if functional) as well as a single-step execution without additional complexity like loops, conditional statements, external resources, or advanced coding techniques commonly included at higher difficulty levels.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm('write that this is a test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5698c1d2-07c4-4325-acc4-5297f380d466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This is a test.\n",
      "\n",
      "\n",
      "The instruction seems to be simple, asking for the writing of just one sentence with specific content and purpose in mind – confirming whether an environment or system works correctly by executing what appears to be straightforward commands. The simplicity lies both in its directness (a command that should yield minimal output if functional) as well as a single-step execution without additional complexity like loops, conditional statements, external resources, or advanced coding techniques commonly included at higher difficulty levels.\n"
     ]
    }
   ],
   "source": [
    "print(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202a3fa6-f470-4462-9728-f6b59774a521",
   "metadata": {},
   "source": [
    "# Running in Docker\n",
    "\n",
    "## Run Docker image\n",
    "```cmd\n",
    "docker run -it \\\n",
    "    -v ollama:/root/.ollama \\\n",
    "    -p 11434:11434 \\\n",
    "    --name ollama \\\n",
    "    ollama/ollama\n",
    "```\n",
    "\n",
    "## Pull Model\n",
    "\n",
    "```cmd\n",
    "docker exec -it ollama bash\n",
    "ollama pull phi3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c66304-3b8f-4a8d-b485-45e4a6662b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
